{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Machine-Learning TD\n",
                "By Corentin Meyer, PhD Student @ CSTB - iCube, 04/10 ESBS\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# PART 1: Exploration, formating and data split\n",
                "\n",
                "## The Data that we will use\n",
                "## [Stroke Prediction Dataset](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset)\n",
                "### **Context**\n",
                "According to the World Health Organization (WHO) stroke is the 2nd leading cause of death globally, responsible for approximately 11% of total deaths.\n",
                "This dataset is used to predict whether a patient is likely to get stroke based on the input parameters like gender, age, various diseases, and smoking status. Each row in the data provides relavant information about the patient.\n",
                "Attribute Information\n",
                "### **11 clinical features for predicting stroke events**\n",
                "1. **id:** unique identifier\n",
                "2. **gender:** \"Male\", \"Female\" or \"Other\"\n",
                "3. **age**: age of the patient\n",
                "4. **hypertension**: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n",
                "5. **heart_disease**: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n",
                "6. **ever_married**: \"No\" or \"Yes\"\n",
                "7. **work_type**: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n",
                "8. **Residence_type**: \"Rural\" or \"Urban\"\n",
                "9. **avg_glucose_level**: average glucose level in blood\n",
                "10. **bmi**: body mass index\n",
                "11. **smoking_status**: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n",
                "12. **stroke**: 1 if the patient had a stroke or 0 if not  \n",
                "* Note: \"Unknown\" in smoking_status means that the information is unavailable for this patient"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Tasks: Data Exploration**\n",
                "1. Import the data (and set the dataframe index to the ID column)\n",
                "2. Print the shape of the dataset and the first 5 lines\n",
                "3. Calculate the ratio stroke/non-stroke  \n",
                "4. Plot histogram of the \"age\" column separate by stroke vs non-stroke status.\n",
                "5. Print the type of each columns (number, object...)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Questions:**\n",
                "1. How many entries (patients) are in the dataset ?\n",
                "2. How many columns (features) ?\n",
                "3. Plot the histogram of the age feature. Do separate histogram for stroke vs non-stroke patients\n",
                "4. What is the percentage of the patients that had a stroke ?\n",
                "5. Show the type of data in each columns. What type of processing will we have to do for each type ?"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Import the data (df variable) using read_csv() and set the index with .set_index()\n",
                "df = \n",
                "\n",
                "# Print the shape of the dataframe and the head using df.shape and df.head()\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Use value_counts() on the \"stroke\" column. Check value_counts parameter to normalize !\n",
                "\n",
                "\n",
                "# Use pandas built-in dataframe .hist() methods to plot the histo of the \"age\" column. Check hist parameters to group by !\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Print the \"dtypes\" attribute of dataframe\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Tasks: Data Formating**\n",
                "You will now do the pre-processing of data.\n",
                "For each type of object you will have to process them in a usable format for ML algorithm.\n",
                "\n",
                "## **Questions**\n",
                "1. What columns are categorical data, what columns are numeric.\n",
                "2. What columns are already ready to be used and needs no change.\n",
                "3. What type of processing do you need to do on categorical data and why\n",
                "4. What type of processing do you need to do on numeric data and why\n",
                "5. What columns contains missing data ? What type of processing do you need to do in this case.\n",
                "\n",
                "## **Ressources**:\n",
                "[Google's Class: Transforming Numeric Data](https://developers.google.com/machine-learning/data-prep/transform/transform-numeric)  \n",
                "[Google's Class: Transforming Categorical Data](https://developers.google.com/machine-learning/data-prep/transform/transform-categorical)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "![Categorial Feature](https://i.imgur.com/mRFk0Sh.png)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import numpy as np\n",
                "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
                "from sklearn.experimental import enable_iterative_imputer\n",
                "from sklearn.impute import IterativeImputer\n",
                "\n",
                "# Create lists with columns names for each processing categories\n",
                "columns_categorical = [\"...\"] # 5 Columns\n",
                "columns_numeric = [\"...\"] # 3 Columns\n",
                "columns_nothing = [\"...\"] # 3 Columns\n",
                "\n",
                "# Categorial data to numeric: do one hot encoding ( OneHotEncoder(), .fit_transform() and .toarray() )\n",
                "# I give you the OneHot example. Do something similar for the Scaling of numerics data !\n",
                "enc = OneHotEncoder()\n",
                "X_cat = df[columns_categorical]\n",
                "X_cat_onehot = enc.fit_transform(X_cat).toarray()\n",
                "X_cat_columns_onehot = enc.get_feature_names()\n",
                "\n",
                "# Numeric data: do scaling (-1;+1) (StandardScaler() and .fit_transform())\n",
                "X_num = \n",
                "X_num_scaled = \n",
                "X_num_columns_scaled = \n",
                "\n",
                "# Nothing-To-Do Cols: just select them and convert the pandas dataframe to numpy array ( .to_numpy() )\n",
                "X_nothing_to_do = \n",
                "\n",
                "# Combine the nothing_to_do_columns, one-hot cols, and numeric data into a numpy array\n",
                "# using np.concatenate ; Care for the axis parameter\n",
                "array_data = \n",
                "\n",
                "# Finally handle Missing Data: Use imputer to predict them ( IterativeImputer() and .fit_transform() and store results in array_data )\n",
                "imp_mean = \n",
                "array_data = \n",
                "\n",
                "# You can recreate a DataFrame for pretty printing, but this is optional.\n",
                "df_data  = pd.DataFrame(data=array_data, columns=list(X_cat_columns_onehot) + list(X_num_columns_scaled) + columns_nothing)\n",
                "df_data"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Tasks: Data Train/Test Spliting**\n",
                "Now you can split the data between training and testing data.\n",
                "\n",
                "## **Questions**\n",
                "1. What train/test ratio should you use.\n",
                "2. How many entries are in your train dataset and in your test dataset.\n",
                "3. Verify that you have the same stroke / no-stroke ratio between train and test dataset."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "# From your numpy array that you created, separate the X columns (features: mutiples columns) and the Y column (label: last column) in two variables\n",
                "X = \n",
                "Y = \n",
                "\n",
                "# Use train_test_split() using X and Y with the ratio you selected.\n",
                "X_train, X_test, Y_train, Y_test = \n",
                "\n",
                "# Print X_train and X_test shape, use np.unique() with return_counts parameter on Y_train, x_test to get the 0/1 ratio\n",
                "print()\n",
                "print()\n",
                "print(np.unique(\"...\")[1])\n",
                "print(np.unique(\"...\")[1])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# PART 2: Create your machine-learning model"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Tasks: Choose a model and do basic evaluation**\n",
                "Select from scikit-learn a model and train it (fit) with the train data. Then calculate the accuracy of the model on the test data. Plot the confusion matrix of the test data classification.\n",
                "\n",
                "## **Questions:**\n",
                "1. Which model did you choose and why ? Have you set any particular (hyper)parameters ?\n",
                "2. What accuracy-score do you get and what conclusion can you take ?\n",
                "3. What do you observe on the confusion matrix and what conclusion can you take ?"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "![Accuracy and Confusion Matrix](https://i.imgur.com/EAf5SNh.png)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import plot_confusion_matrix\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Select a model from: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning\n",
                "\n",
                "# For example: create a clf variable containing a RandomForestClassifier(). \n",
                "# Don't hesitate to tweak its parameters as you like ! You can experiment.\n",
                "# Use fit() on clf variable with your x_train and Y_train to train the model.\n",
                "clf = \n",
                "\n",
                "# Using the .score() method of clf, print its accuracy on x_test, Y_test\n",
                "print()\n",
                "# Plot the confusion matrix using plot_confusion_matrix with clf, x_test, Y_test)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Tasks: Correct the previous issue**\n",
                "You will now try to downsample your majority class to the level of minority class to have a 50/50 ratio and re-do a train/test split.  \n",
                "Then you will re-train a new model with the new ratio-corrected data and get accuracy+confusion matrix plot.\n",
                "Don't only predict the class, but also show the prediction probability for all data in the test set !\n",
                "## **Questions**\n",
                "1. What accuracy-score do you get with the new model and what conclusion can you take.\n",
                "2. What do you observe on the confusion matrix and what conclusion can you take.\n",
                "3. Did you managed to print the probability of each prediction ? What's the shape of the prediction probability output ? Is there a high variance between the different test entries in probability ?"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "![Downsampling](https://i.imgur.com/QPOuSKk.png)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Graphical Recap of our data-variable as we are having plenty of them !\n",
                "### **Here you will be creating variable called X_down, X_down_test..., so you don't get lost with all names, watch this diagram !**\n",
                "![Variable Diagram](https://i.imgur.com/tShIU1R.png)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Using this tutorial: https://chrisalbon.com/code/machine_learning/preprocessing_structured_data/handling_imbalanced_classes_with_downsampling/\n",
                "# We will downsample our data by using the code in the \"Downsample Majority Class To Match Minority Class\" section.\n",
                "# In the tutorial, 1 is the majority class, here it is 0. It will be important to make a change in the \"np.random.choice\" line.\n",
                "np.random.seed(777)\n",
                "\n",
                "# Get index of rows for each class (0/1)\n",
                "i_class0 = np.where(Y == 0)[0]\n",
                "i_class1 = \"...\"\n",
                "# Total Number of observations in each class\n",
                "n_class0 = \"...\"\n",
                "n_class1 = \"...\"\n",
                "# For every observation of class 1, randomly select (sample) from index list of class 0 without replacement\n",
                "i_class0_downsampled = \"...\"\n",
                "\n",
                "# Join together the downsampled class 0's target vector with class 1's target vector\n",
                "Y_down = np.hstack((Y[i_class0_downsampled], Y[i_class1]))\n",
                "X_down = np.vstack((X[i_class0_downsampled], X[i_class1]))\n",
                "\n",
                "# Re-do a train/test split but this time on the new X_down and Y_down data (downsampled).\n",
                "# Call the new variables X_train_down, X_test_down, Y_train_down, Y_test_down for example.\n",
                "X_train_down, X_test_down, Y_train_down, Y_test_down = \n",
                "\n",
                "# Recreate a model called clf_down with RandomForestClassifier()\n",
                "# And .fit() it this time on X_train_down, Y_train_down\n",
                "clf_down = \n",
                "\n",
                "# Calculate its accuracy using the .score() methods on X_test_down, Y_test_down\n",
                "print()\n",
                "# Plot the confusion matrix as before, but with clf_down, X_test_down, Y_test_down\n",
                "\n",
                "\n",
                "# Print the prediction probablity of the first 10 test data points using .predict_proba() of the model.\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# PART 3: Evaluate your model"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Tasks: See all common metrics and evalute both models !**\n",
                "In this last part you will have to calculate all relevant metrics for a binary classification to compare your two models.  \n",
                "Make a table containing the results for both models in terms of: accuracy, balance accuracy, F1 Score, sensitivity (recall), specificity, Precision and confusion matrix data (True Pos., True Neg., False Pos., False Neg.)\n",
                "\n",
                "## **Questions:**\n",
                "1. Which model have the accuracy ?\n",
                "2. Which model have the best area under the curve (AUC) for the ROC-curve ?\n",
                "3. Which model have the best F1-Score and sensitivity ?\n",
                "4. Eventually, which model is better according to you based on the metrics ?"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "![Roc Curve](https://i.imgur.com/DFw604d.png)\n",
                "![F1-Score](https://i.imgur.com/8b5AkS3.png)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Calculate all relevant metrics for a binary classification\n",
                "# Using Scikit score function: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
                "# Calculate: Accuracy, Balanced Accuracy, F1 Score, Sensitivity (Recall), Specificity, Precision, TP TN FP FN\n",
                "# Also plot the ROC Curve and the Precision-Recall Curve using scikit built-in function\n",
                "\n",
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.metrics import balanced_accuracy_score\n",
                "from sklearn.metrics import recall_score\n",
                "from sklearn.metrics import confusion_matrix\n",
                "from sklearn.metrics import precision_score\n",
                "from sklearn.metrics import f1_score\n",
                "from sklearn.metrics import plot_precision_recall_curve, plot_roc_curve\n",
                "\n",
                "def get_all_metrics(clf, X_test, Y_test):\n",
                "\t\"\"\"\"Function that returns all the metrics for a given classifier and test data\"\"\"\n",
                "\t# Use classifier to predict the Y label of X_test data with .predict()\n",
                "\ty_pred = \"...\"\n",
                "\n",
                "\t# Confusion Matrix results\n",
                "\ttn, fp, fn, tp = confusion_matrix(Y_test, y_pred).ravel()\n",
                "\n",
                "\t# Calculate the metrics: balanced accuracy, recall, precision, F1-score. Accuracy and Specificity are already done.\n",
                "\t# Fill the \"...\"\n",
                "\tac = accuracy_score(Y_test, y_pred)\n",
                "\tbac = \"...\"\n",
                "\tre = \"...\"\n",
                "\tpr = \"...\"\n",
                "\tf1 = \"...\"\n",
                "\ttry: sp = tn/float(tn+fp)\n",
                "\texcept: sp = 0\n",
                "\n",
                "\treturn [bac, ac, f1, re, sp, pr, tp, tn, fp, fn]\n",
                "\n",
                "def make_table_clf(clf, clf_down, X_test, Y_test, X_test_down, Y_test_down):\n",
                "\t\"\"\"\"Use the get_all_metrics function to make a table to compare two models\"\"\"\n",
                "\tresults = get_all_metrics(clf, X_test, Y_test)\n",
                "\tresults_down = get_all_metrics(clf_down, X_test_down, Y_test_down)\n",
                "\tdf = pd.DataFrame([[i for i in results], [j for j in results_down]], columns=[\"Balanced-Accuracy\", \"Accuracy\", \"F1-Score\", \"Sensitivity (Recall)\", \"Specificity\", \"Precision\", \"TP\",\" TN\", \"FP\", \"FN\"], index=[\"CLF\",\"CLF DownSampled\"])\n",
                "\treturn df"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Use the make_table_clf() function to compare the metrics of both models !\n",
                "make_table_clf(\"...\") # Fill with clf, clf down, and its respective X and Y data"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "print(\"ROC Curve and Prec/Recall Cruve Results For Initial Classifier: \")\n",
                "plot_precision_recall_curve(clf, X_test, Y_test)\n",
                "plot_roc_curve(clf, X_test, Y_test)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Do The same as the cell above, but with clf_down model, and X_test_down and Y_test_down data to compare the results !\n",
                "print(\"ROC Curve and Prec/Recall Cruve Results For Downsampled Classifier: \")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# BONUS 1: Do Cross-validation instead of simple test/train split."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Tasks:**  \n",
                "Instead of a simple Test/Train split, we will do cross-validation. This means that we will train multiple models with different splits, so that all data have been used for training and all for testing. Then we will average the results of all models.  \n",
                "For example, if we do a 80/20% train/test split, then we would need to do a 5 fold cross-validation so that each data has been in the test-set at least once.  \n",
                "Find a way to do \"stratified k fold\", calculate \"cross val score\" with scikit and print the mean and standard deviation of the score.\n",
                "## **Questions:**  \n",
                "1. What is the point of cross-validation ? Did it increase performance ? If not, what is it useful for ?"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "![Cross-validation](https://fr.mathworks.com/discovery/cross-validation/_jcr_content/mainParsys/image.adapt.full.medium.jpg/1623131646985.jpg)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from sklearn.model_selection import StratifiedKFold\n",
                "from sklearn.model_selection import cross_val_score\n",
                "\n",
                "# Create a cv variable using the StratifiedKFold with 5 folds.\n",
                "cv = \n",
                "\n",
                "# Use the cross_val_score with your clf_down model, your train data, cv varaible and select f1 as scoring method.\n",
                "# Store the results in a cross_scores variables\n",
                "cross_scores = cross_val_score(\"....\")\n",
                "\n",
                "# Print the full cross validation scores, calculate the mean and the standard deviation of these 5 folds.\n",
                "print()\n",
                "print()\n",
                "print()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# BONUS 2:  Automatic hyper-parameters tuning"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Tasks:**\n",
                "We will use optuna to automatically find the best parameters for the chosen ML Algorithm (Random Forest here). We define a number of trials (50), a scoring metrics to maximize (F1 Score) and a parameters space to explore (params_grid).  \n",
                "In the end we will have a model with the best parameters that have been found and we will compared its metrics to our previous classifier (clf_down) without optimisation.  \n",
                "Try to tweak the hyper parameters spaces to shrink or expand it. Try to optimize another ML Algorithm.  \n",
                "## **Questions:**  \n",
                "1. What are the best parameters detected ? Are your best parameters different from the one of other students ? Why ?\n",
                "2. Did the metrics improved ? Was the optimisation useful ?\n",
                "\n",
                "## **Warnings**\n",
                "This is a pretty long task depending of your computed because the program will train and test 50+ models with differents parameters. Your computer will heat up a bit for a few minutes, so don't run it if you don't want it to happens !"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "![Hyerparameters Tuning](https://i.imgur.com/3plYcqn.png)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# If you are using Google Colab, uncomment the next line starting with ! and run the cell to install optuna\n",
                "# !pip install optuna"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import optuna\n",
                "from sklearn.base import clone\n",
                "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
                "\n",
                "def make_table_clf_opti(clf, clf_down, X_test, Y_test, X_test_down, Y_test_down):\n",
                "\tresults = get_all_metrics(clf, X_test, Y_test)\n",
                "\tresults_down = get_all_metrics(clf_down, X_test_down, Y_test_down)\n",
                "\tdf = pd.DataFrame([[i for i in results], [j for j in results_down]], columns=[\"Balanced-Accuracy\", \"Accuracy\", \"F1-Score\", \"Sensitivity (Recall)\", \"Specificity\", \"Precision\", \"TP\",\" TN\", \"FP\", \"FN\"], index=[\"CLF Down\",\"CLF Down Optimized\"])\n",
                "\treturn df\n",
                "\n",
                "def objective_RF(\n",
                "    trial, est, x_train, Y_train, param_grid, scoring_metric):\n",
                "    \"\"\"\n",
                "    A function that is used by Optuna to get the scoring of a model given the parameters of a specific trial.\n",
                "    \"\"\"\n",
                "    params = {\n",
                "        \"n_estimators\": trial.suggest_int(\n",
                "            \"n_estimators\", param_grid[\"n_estimators\"][0], param_grid[\"n_estimators\"][1]\n",
                "        ),\n",
                "        \"criterion\": trial.suggest_categorical(\"criterion\", param_grid[\"criterion\"]),\n",
                "        \"max_depth\": trial.suggest_int(\n",
                "            \"max_depth\", param_grid[\"max_depth\"][0], param_grid[\"max_depth\"][1]\n",
                "        ),\n",
                "        \"min_samples_split\": trial.suggest_int(\n",
                "            \"min_samples_split\",\n",
                "            param_grid[\"min_samples_split\"][0],\n",
                "            param_grid[\"min_samples_split\"][1],\n",
                "        ),\n",
                "        \"min_samples_leaf\": trial.suggest_int(\n",
                "            \"min_samples_leaf\",\n",
                "            param_grid[\"min_samples_leaf\"][0],\n",
                "            param_grid[\"min_samples_leaf\"][1],\n",
                "        ),\n",
                "        \"max_features\": trial.suggest_categorical(\n",
                "            \"max_features\", param_grid[\"max_features\"]\n",
                "        ),\n",
                "        \"bootstrap\": trial.suggest_categorical(\"bootstrap\", param_grid[\"bootstrap\"]),\n",
                "        \"oob_score\": trial.suggest_categorical(\"oob_score\", param_grid[\"oob_score\"]),\n",
                "        \"n_jobs\": trial.suggest_categorical(\"n_jobs\", param_grid[\"n_jobs\"]),\n",
                "        \"class_weight\": trial.suggest_categorical(\n",
                "            \"class_weight\", param_grid[\"class_weight\"]\n",
                "        ),\n",
                "    }\n",
                "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
                "    model = clone(est).set_params(**params)\n",
                "    performance = np.mean(\n",
                "        cross_val_score(\n",
                "            model,\n",
                "            x_train,\n",
                "            Y_train,\n",
                "            cv=cv,\n",
                "            scoring=scoring_metric,\n",
                "            error_score=\"raise\",\n",
                "        )\n",
                "    )\n",
                "    return performance\n",
                "\n",
                "# Random Forest parameters space\n",
                "param_grid = {'n_estimators': [10,400],\n",
                "                'criterion' : ['gini', 'entropy'],\n",
                "                'max_depth' : [1, 15],\n",
                "                'min_samples_split' : [2, 50], \n",
                "                'min_samples_leaf' : [1, 50],\n",
                "                'max_features' : [None, 'auto','log2'],\n",
                "                'bootstrap' : [True],\n",
                "                'oob_score' : [False, True],\n",
                "                'n_jobs' : [-1],\n",
                "                'class_weight' : [None, 'balanced']}\n",
                "\n",
                "# Run Hyperparameter Sweep: first we set up some settings.\n",
                "n_trials = 50\n",
                "scoring_metric = \"f1\"\n",
                "timeout = 300 \n",
                "est = RandomForestClassifier()\n",
                "sampler = optuna.samplers.TPESampler()\n",
                "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
                "optuna.logging.set_verbosity(optuna.logging.CRITICAL)\n",
                "\n",
                "# We launch the optimization using the previous function as score-returning.\n",
                "study.optimize(\n",
                "    lambda trial: objective_RF(\n",
                "        trial, est, X_train_down, Y_train_down, param_grid, scoring_metric),\n",
                "    n_trials=n_trials,\n",
                "    timeout=timeout,\n",
                "    catch=(ValueError,),\n",
                ")\n",
                "# We retrieve the best results now that the optimization is finished.\n",
                "print(\"Best trial:\")\n",
                "best_trial = study.best_trial\n",
                "print(\"  Score: \", best_trial.value)\n",
                "print(\"  Params: \")\n",
                "for key, value in best_trial.params.items():\n",
                "    print(\"    {}: {}\".format(key, value))\n",
                "\n",
                "# Train model using 'best' hyperparameters\n",
                "est = RandomForestClassifier()\n",
                "clf = clone(est).set_params(**best_trial.params)\n",
                "\n",
                "model = clf.fit(X_train_down, Y_train_down)\n",
                "y_pred = clf.predict(X_test_down)\n",
                "\n",
                "plot_precision_recall_curve(model, X_test_down, Y_test_down)\n",
                "plot_roc_curve(model, X_test_down, Y_test_down)\n",
                "make_table_clf_opti(clf_down, model, X_test_down, Y_test_down, X_test_down, Y_test_down)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Additional Ressources\n",
                "\n",
                "Google's Class lists and ressources on ML [https://developers.google.com/machine-learning/crash-course](https://developers.google.com/machine-learning/crash-course)  \n",
                "If you want to become an AI Expert: AI Rodmap [https://i.am.ai/roadmap](https://i.am.ai/roadmap)  \n",
                "Visualisation in Python [https://www.python-graph-gallery.com/](https://www.python-graph-gallery.com/)  \n",
                "Public Dataset to create projects [https://github.com/awesomedata/awesome-public-datasets](https://github.com/awesomedata/awesome-public-datasets)  \n",
                "Machine Learning Competitions with Prize [https://www.kaggle.com/](https://www.kaggle.com/)"
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.5 64-bit ('TD_ML': conda)"
        },
        "interpreter": {
            "hash": "b1f4f77d01ceeeb3f1b50751faca703c6ff6e53a2ece845b812c7f39fafa84f3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}